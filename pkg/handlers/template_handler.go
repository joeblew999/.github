package handlers

import (
	"context"
	"fmt"
	"log"
	"os/exec"
	"strings"
	"time"

	"github.com/nats-io/nats.go"
	// This would be generated by bee from our protobuf schema
	// eventsv1 "github.com/joeblew999/.github/pkg/events/v1"
)

// TemplateChangedHandler demonstrates bee-style event handling
// This would be generated by bee from bee.yaml configuration
type TemplateChangedHandler struct {
	nc              *nats.Conn
	terraformBinary string
	githubOrg       string
	region          string
}

// NewTemplateChangedHandler creates a new handler instance
func NewTemplateChangedHandler(nc *nats.Conn, terraformBinary, githubOrg, region string) *TemplateChangedHandler {
	return &TemplateChangedHandler{
		nc:              nc,
		terraformBinary: terraformBinary,
		githubOrg:       githubOrg,
		region:          region,
	}
}

// Handle processes template change events with type safety
// In a real bee implementation, this signature would be generated from protobuf
func (h *TemplateChangedHandler) Handle(ctx context.Context, event interface{}) error {
	// In real bee implementation, event would be *eventsv1.TemplateChangedEvent
	log.Printf("ðŸ”„ Processing template change event for org: %s", h.githubOrg)

	// Extract event data (this would be type-safe with bee)
	eventData := event.(map[string]interface{})

	impactLevel := eventData["impact_level"].(string)
	changedFiles := eventData["changed_files"].([]string)
	commitSha := eventData["commit_sha"].(string)

	log.Printf("   Impact Level: %s", impactLevel)
	log.Printf("   Changed Files: %v", changedFiles)
	log.Printf("   Commit: %s", commitSha)

	// Business logic: decide if infrastructure scaling is needed
	if h.shouldScaleInfrastructure(impactLevel, changedFiles) {
		log.Printf("ðŸš€ Triggering infrastructure scaling...")

		if err := h.triggerTerraformScaling(ctx, impactLevel); err != nil {
			return fmt.Errorf("failed to trigger scaling: %w", err)
		}

		// Publish scaling event to NATS
		scalingEvent := map[string]interface{}{
			"org":                 h.githubOrg,
			"region":              h.region,
			"direction":           "UP",
			"reason":              "HIGH_IMPACT_TEMPLATE_CHANGE",
			"timestamp":           time.Now().UTC(),
			"triggered_by_commit": commitSha,
		}

		if err := h.publishEvent("nats.infrastructure_scaling", scalingEvent); err != nil {
			log.Printf("âš ï¸ Failed to publish scaling event: %v", err)
		}
	}

	// Always trigger template regeneration
	log.Printf("ðŸ“ Triggering template regeneration...")

	regenEvent := map[string]interface{}{
		"org":             h.githubOrg,
		"repo":            ".github",
		"triggered_by":    "template_change_handler",
		"reason":          "template_updated",
		"target_files":    changedFiles,
		"timestamp":       time.Now().UTC(),
		"priority":        h.determinePriority(impactLevel),
		"idempotency_key": fmt.Sprintf("template-change-%s", commitSha),
	}

	if err := h.publishEvent("github.regeneration_requested", regenEvent); err != nil {
		return fmt.Errorf("failed to publish regeneration event: %w", err)
	}

	log.Printf("âœ… Template change event processed successfully")
	return nil
}

// shouldScaleInfrastructure determines if infrastructure scaling is needed
func (h *TemplateChangedHandler) shouldScaleInfrastructure(impactLevel string, changedFiles []string) bool {
	// High or critical impact changes trigger scaling
	if impactLevel == "IMPACT_LEVEL_HIGH" || impactLevel == "IMPACT_LEVEL_CRITICAL" {
		return true
	}

	// Check if workflow files changed (might increase load)
	for _, file := range changedFiles {
		if strings.Contains(file, "workflows/") {
			return true
		}
	}

	return false
}

// triggerTerraformScaling executes Terraform to scale infrastructure
func (h *TemplateChangedHandler) triggerTerraformScaling(ctx context.Context, impactLevel string) error {
	log.Printf("ðŸ”§ Executing Terraform scaling operation...")

	// Determine scaling parameters based on impact level
	var loadFactor string
	var terraformConfig string

	switch impactLevel {
	case "IMPACT_LEVEL_HIGH":
		loadFactor = "2.0"
		terraformConfig = "terraform/nats-regional.tf"
	case "IMPACT_LEVEL_CRITICAL":
		loadFactor = "3.0"
		terraformConfig = "terraform/nats-github-infrastructure.tf"
	default:
		loadFactor = "1.5"
		terraformConfig = "terraform/nats-regional.tf"
	}

	// Build Terraform command
	cmd := exec.CommandContext(ctx, h.terraformBinary, "apply", "-auto-approve",
		fmt.Sprintf("-var=github_org=%s", h.githubOrg),
		fmt.Sprintf("-var=region=%s", h.region),
		fmt.Sprintf("-var=load_factor=%s", loadFactor),
		terraformConfig,
	)

	// Execute Terraform
	output, err := cmd.CombinedOutput()
	if err != nil {
		log.Printf("âŒ Terraform failed: %s", string(output))
		return fmt.Errorf("terraform apply failed: %w", err)
	}

	log.Printf("âœ… Terraform scaling completed: %s", string(output))

	// Publish Terraform operation result
	terraformEvent := map[string]interface{}{
		"org":          h.githubOrg,
		"operation_id": fmt.Sprintf("scale-%d", time.Now().Unix()),
		"operation":    "TERRAFORM_OPERATION_APPLY",
		"status":       "TERRAFORM_STATUS_SUCCESS",
		"timestamp":    time.Now().UTC(),
		"config":       terraformConfig,
		"load_factor":  loadFactor,
	}

	return h.publishEvent("terraform.operation", terraformEvent)
}

// determinePriority maps impact level to processing priority
func (h *TemplateChangedHandler) determinePriority(impactLevel string) string {
	switch impactLevel {
	case "IMPACT_LEVEL_CRITICAL":
		return "PRIORITY_URGENT"
	case "IMPACT_LEVEL_HIGH":
		return "PRIORITY_HIGH"
	case "IMPACT_LEVEL_MEDIUM":
		return "PRIORITY_NORMAL"
	default:
		return "PRIORITY_LOW"
	}
}

// publishEvent publishes an event to NATS
func (h *TemplateChangedHandler) publishEvent(subject string, event interface{}) error {
	// In a real implementation, this would use protobuf serialization
	data := fmt.Sprintf("%+v", event) // Simplified for demo

	fullSubject := fmt.Sprintf("%s.%s", subject, h.githubOrg)

	if err := h.nc.Publish(fullSubject, []byte(data)); err != nil {
		return fmt.Errorf("failed to publish to %s: %w", fullSubject, err)
	}

	log.Printf("ðŸ“¡ Published event to %s", fullSubject)
	return nil
}

// SystemHealthHandler demonstrates health monitoring with bee
type SystemHealthHandler struct {
	nc        *nats.Conn
	githubOrg string
}

// Handle processes system health events
func (h *SystemHealthHandler) Handle(ctx context.Context, event interface{}) error {
	log.Printf("ðŸ’“ Processing system health event for org: %s", h.githubOrg)

	// In real bee implementation, this would be type-safe
	healthData := event.(map[string]interface{})

	status := healthData["status"].(string)
	eventStats := healthData["event_stats"].(map[string]interface{})
	infrastructure := healthData["infrastructure"].(map[string]interface{})

	// Check for concerning metrics
	eventsInQueue := eventStats["events_in_queue"].(int64)
	cpuUsage := infrastructure["cpu_usage_percent"].(float64)

	log.Printf("   System Status: %s", status)
	log.Printf("   Events in Queue: %d", eventsInQueue)
	log.Printf("   CPU Usage: %.1f%%", cpuUsage)

	// Trigger scaling if needed
	if eventsInQueue > 1000 || cpuUsage > 80.0 {
		log.Printf("ðŸš¨ System under load - triggering scaling...")

		scalingEvent := map[string]interface{}{
			"org":       h.githubOrg,
			"region":    "auto",
			"direction": "UP",
			"reason":    "HIGH_SYSTEM_LOAD",
			"timestamp": time.Now().UTC(),
			"metrics": map[string]interface{}{
				"queue_depth": eventsInQueue,
				"cpu_usage":   cpuUsage,
			},
		}

		return h.publishEvent("nats.infrastructure_scaling", scalingEvent)
	}

	log.Printf("âœ… System health within normal parameters")
	return nil
}

// publishEvent for SystemHealthHandler
func (h *SystemHealthHandler) publishEvent(subject string, event interface{}) error {
	data := fmt.Sprintf("%+v", event)
	fullSubject := fmt.Sprintf("%s.%s", subject, h.githubOrg)

	if err := h.nc.Publish(fullSubject, []byte(data)); err != nil {
		return fmt.Errorf("failed to publish to %s: %w", fullSubject, err)
	}

	log.Printf("ðŸ“¡ Published health-triggered event to %s", fullSubject)
	return nil
}
